{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Portable application framework\n",
    "In this notebook a tutorial on how to use the portable application framework is presented.\n",
    "The framework is based on the principle that, to build portable applications based on ontologies schema (Brick in this case), the following main steps are sufficient:\n",
    "- The validation of the metadata requirements of the application using the SHACL shapes framework.\n",
    "- The query step to fetch the data from the graph.\n",
    "- The analysis step to analyze the data and store the results.\n",
    "\n",
    "*Continue*\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfb756137b6e0efe"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# import os\n",
    "# import brickschema\n",
    "# from app.utils.util import ensure_dir, list_files\n",
    "# from app.utils.util_driver import driver_data_fetch\n",
    "# from app import Application\n",
    "# from app.utils.util_check import check_sensor, check_log_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:58:51.715312800Z",
     "start_time": "2024-02-14T10:58:51.674389200Z"
    }
   },
   "id": "1458701a0c42f662"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# folder = os.path.join(\"data\", \"LBNL_FDD_Dataset_SDAHU_PQ\")\n",
    "# ensure_dir(folder)\n",
    "# files = list_files(folder, file_formats=[\".csv\", \".parquet\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:58:51.715312800Z",
     "start_time": "2024-02-14T10:58:51.674389200Z"
    }
   },
   "id": "54df11caa3781580"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data fetching and graph instantiation\n",
    "To use the application, two main inputs are needed: \n",
    "- The Turtle file containing the graph;\n",
    "- A dataframe to analyze;\n",
    "- (optional) A configuration file if is needed in the analyze function (to make it more parametric)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9620fecf1cda5073"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                           SA_TEMPSPT    SA_TEMP    OA_TEMP    RA_TEMP  \\\ntime                                                                     \n2018-01-01 01:00:00+00:00   12.880003  19.097044 -12.024994  20.189861   \n2018-01-01 01:01:00+00:00   12.880003  19.097044 -12.199982  20.193256   \n2018-01-01 01:02:00+00:00   12.880003  19.097044 -12.191649  20.196544   \n2018-01-01 01:03:00+00:00   12.880003  19.097014 -12.183319  20.199711   \n2018-01-01 01:04:00+00:00   12.880003  19.097014 -12.174988  20.202767   \n\n                             MA_TEMP  CHWC_VLV_DM  OA_DMPR_DM  \ntime                                                           \n2018-01-01 01:00:00+00:00  19.097044          0.0         0.0  \n2018-01-01 01:01:00+00:00  19.097044          0.0         0.0  \n2018-01-01 01:02:00+00:00  19.097044          0.0         0.0  \n2018-01-01 01:03:00+00:00  19.097014          0.0         0.0  \n2018-01-01 01:04:00+00:00  19.097014          0.0         0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SA_TEMPSPT</th>\n      <th>SA_TEMP</th>\n      <th>OA_TEMP</th>\n      <th>RA_TEMP</th>\n      <th>MA_TEMP</th>\n      <th>CHWC_VLV_DM</th>\n      <th>OA_DMPR_DM</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-01 01:00:00+00:00</th>\n      <td>12.880003</td>\n      <td>19.097044</td>\n      <td>-12.024994</td>\n      <td>20.189861</td>\n      <td>19.097044</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:01:00+00:00</th>\n      <td>12.880003</td>\n      <td>19.097044</td>\n      <td>-12.199982</td>\n      <td>20.193256</td>\n      <td>19.097044</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:02:00+00:00</th>\n      <td>12.880003</td>\n      <td>19.097044</td>\n      <td>-12.191649</td>\n      <td>20.196544</td>\n      <td>19.097044</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:03:00+00:00</th>\n      <td>12.880003</td>\n      <td>19.097014</td>\n      <td>-12.183319</td>\n      <td>20.199711</td>\n      <td>19.097014</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:04:00+00:00</th>\n      <td>12.880003</td>\n      <td>19.097014</td>\n      <td>-12.174988</td>\n      <td>20.202767</td>\n      <td>19.097014</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasource = \"AHU_annual\"\n",
    "# df = driver_data_fetch(folder, \"AHU_annual.parquet\")\n",
    "# graph = brickschema.Graph().parse(\n",
    "#         os.path.join(\"data\", \"LBNL_FDD_Dataset_SDAHU\", \"LBNL_FDD_Data_Sets_SDAHU_ttl.ttl\"))\n",
    "# config = {\n",
    "#             'datasource': datasource,\n",
    "#             'aggregation': 15,\n",
    "#             'transient_cutoff': 0.01,\n",
    "#             'valves_cutoff': 0.01,\n",
    "#             'damper_cutoff': 0.0,\n",
    "#             'temperature_error': 1,\n",
    "#             'temperature_sensor_variance_threshold': 0.01,\n",
    "#             'control_sensor_variance_threshold': 0.01,\n",
    "#             'damper_min_oa_threshold': 0.3,\n",
    "#             'diff_damper_oaf_threshold': 0.3,\n",
    "#             'sat_reset_threshold': 0.1\n",
    "#         }\n",
    "# df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:58:52.254148700Z",
     "start_time": "2024-02-14T10:58:51.688010400Z"
    }
   },
   "id": "4ef8cb79c17f6018"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Application instantiation\n",
    "\n",
    "To create an application, from the command line the following command is used:\n",
    "```bash\n",
    "\n",
    "```\n",
    "This command will create a folder with the name of the application and the necessary files to run the application, which are:\n",
    "\n",
    "- *config.yaml*: a configuration file with details of the application such as name, author, description, etc...\n",
    "- *manifest.ttl*: the file containing the metadata requirements of the application in form of SHACL shapes.\n",
    "- *query.rq*: the file containing the SPARQL query to be executed on the graph.\n",
    "- *README.md*: a file containing the description of the application for documentation purposes.\n",
    "- *analyze.py* (in the future): the function to be executed on the dataframe.\n",
    "- *cleaning.py* (in the future): the function to be executed on the dataframe to clean and pre-process it.\n",
    "\n",
    "Once this file are created and customized based on the application needs, the application can be instantiated and the data can be fetched and analyzed.\n",
    "\n",
    "In the main code, are just needed the following lines of code:\n",
    "```python\n",
    "from app import Application\n",
    "app = Application(data=df, metadata=graph, app_name='app_name')\n",
    "app.qualify()\n",
    "app.fetch()\n",
    "app.analyze(query, app.res, config)\n",
    "```\n",
    "Where:\n",
    "- app.qualify() will check if the graph has the necessary metadata to run the application.\n",
    "- app.fetch() will query the graph and fetch the data from the dataframe.\n",
    "- app.analyze() uses the custom function (check_sensor in this case) to analyze the data and store the result in app.res, which is a custom ApplicationData class that contains metadata, result and message of the analysis.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cade14e0aa5c9460"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 11:58:52 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# app_check_sensor = Application(data=df, metadata=graph, app_name='app_check_sensor')\n",
    "# app_check_sensor.qualify()\n",
    "# app_check_sensor.fetch()\n",
    "# app_check_sensor.analyze(check_sensor, app_check_sensor.res, config)\n",
    "# check_log_result(\n",
    "#             result=app_check_sensor.res.result,\n",
    "#             check_name=app_check_sensor.details['name'],\n",
    "#             message=app_check_sensor.res.message\n",
    "#         )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:58:52.416451900Z",
     "start_time": "2024-02-14T10:58:52.254148700Z"
    }
   },
   "id": "bb05730995896bfc"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: True\n",
      "Message: \n"
     ]
    }
   ],
   "source": [
    "# print(f\"Result: {app_check_sensor.res.result}\")\n",
    "# print(f\"Message: {app_check_sensor.res.message}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:58:52.419463700Z",
     "start_time": "2024-02-14T10:58:52.411077700Z"
    }
   },
   "id": "53611b73c4577ba0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case the result is a boolean, since the analyses function is just a check on the sensor stucking. The message is a string that contains custom information about the result of the analysis (in this case since the check is passed, no messages are needed)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117e5f108331145e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the application on multiple datasources"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d4ff6c17e4946c0"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### AHU_annual.parquet ###########\n",
      "2024-02-14 12:05:02 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_bias_-2_annual.parquet ###########\n",
      "2024-02-14 12:05:03 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_bias_-4_annual.parquet ###########\n",
      "2024-02-14 12:05:04 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_bias_2_annual.parquet ###########\n",
      "2024-02-14 12:05:04 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_bias_4_annual.parquet ###########\n",
      "2024-02-14 12:05:05 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_leakage_010_annual.parquet ###########\n",
      "2024-02-14 12:05:06 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_leakage_025_annual.parquet ###########\n",
      "2024-02-14 12:05:06 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_leakage_040_annual.parquet ###########\n",
      "2024-02-14 12:05:07 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_leakage_050_annual.parquet ###########\n",
      "2024-02-14 12:05:08 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_stuck_010_annual.parquet ###########\n",
      "2024-02-14 12:05:08 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_stuck_025_annual.parquet ###########\n",
      "2024-02-14 12:05:09 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_stuck_050_annual.parquet ###########\n",
      "2024-02-14 12:05:10 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### coi_stuck_075_annual.parquet ###########\n",
      "2024-02-14 12:05:10 [\u001B[33;1mWARNING\u001B[0m] (util_check.py > check_log_result) \u001B[33;1mCheck Variables = WARNING ⚠️ (Possible sensor freeze/stuck ['cooling_sig_col'])\u001B[0m\n",
      "\n",
      "########### damper_stuck_010_annual.parquet ###########\n",
      "2024-02-14 12:05:11 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### damper_stuck_025_annual.parquet ###########\n",
      "2024-02-14 12:05:12 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### damper_stuck_075_annual.parquet ###########\n",
      "2024-02-14 12:05:12 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### damper_stuck_100_annual_short.parquet ###########\n",
      "2024-02-14 12:05:13 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### oa_bias_-2_annual.parquet ###########\n",
      "2024-02-14 12:05:14 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### oa_bias_-4_annual.parquet ###########\n",
      "2024-02-14 12:05:14 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### oa_bias_2_annual.parquet ###########\n",
      "2024-02-14 12:05:15 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n",
      "\n",
      "########### oa_bias_4_annual.parquet ###########\n",
      "2024-02-14 12:05:16 [\u001B[32;1mINFO\u001B[0m] (util_check.py > check_log_result) \u001B[32;1mCheck Variables = PASSED ✅ \u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# for filename in files:\n",
    "#     print(f'\\n########### {filename} ###########')\n",
    "#     # extract information from filename\n",
    "#     datasource = filename.split('.')[0]\n",
    "#     \n",
    "#     df = driver_data_fetch(folder, filename)\n",
    "#     graph = brickschema.Graph().parse(\n",
    "#             os.path.join(\"data\", \"LBNL_FDD_Dataset_SDAHU\", \"LBNL_FDD_Data_Sets_SDAHU_ttl.ttl\"))\n",
    "#     \n",
    "#     app_check_sensor = Application(data=df, metadata=graph, app_name='app_check_sensor')\n",
    "#     app_check_sensor.qualify()\n",
    "#     app_check_sensor.fetch()\n",
    "#     app_check_sensor.analyze(check_sensor, app_check_sensor.res, config)\n",
    "#     check_log_result(\n",
    "#                 result=app_check_sensor.res.result,\n",
    "#                 check_name=app_check_sensor.details['name'],\n",
    "#                 message=app_check_sensor.res.message\n",
    "#             )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T11:05:16.675937100Z",
     "start_time": "2024-02-14T11:05:01.742654600Z"
    }
   },
   "id": "67b6a488f1ea9232"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5624d14b0e8b2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
